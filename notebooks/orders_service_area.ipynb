{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4857885",
   "metadata": {},
   "source": [
    "# Sipariş Verisi Analizi ve Servis Alanlarının Belirlenmesi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177cbaf",
   "metadata": {},
   "source": [
    "Açıklama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d895c8",
   "metadata": {},
   "source": [
    "## Metodoloji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5488973e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f58572b",
   "metadata": {},
   "source": [
    "## Hazırlık"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3623c4a5",
   "metadata": {},
   "source": [
    "### Çalışma alanının belirlenmesi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9218770",
   "metadata": {},
   "source": [
    "Verileri indirmeden önce, ilgi alanının koordinatlarını tanımlayacağız. Bu koordinatlara dayanarak, veri kümelerini daha ileri işlemeler için kırpabileceğiz ve sonunda seçilen alan için sipariş verisini ve servis alanlarını görüntüleyebileceğiz.\n",
    "\n",
    "Coğrafi koordinatlar cinsinden bir alanı kolayca tanımlamak için [Bounding Box Tool](https://boundingbox.klokantech.com/) adresine giderek bir bölge seçebilir ve koordinatları alabiliriz. Buradaki değerlerin kullanılabilmesi için sol alt köşeden 'CSV' seçeneğini seçtiğinizden emin olun ve ardından köşeli parantez içindeki değerleri kopyalayın. Koordinatların yanı sıra, grafiklerde ve kaydedilen sonuçlarda kullanılacak alan için bir isim belirtmeniz gerekmektedir. Koordinatların WGS84 koordinat sisteminde (EPSG:4326) belirtilmektedir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee18cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## name of the area\n",
    "areaname = 'Bursa'\n",
    "# bbox = [longitude_min, latitude_min, longitude_max, latitude_max]\n",
    "bbox = [28.753995,40.108817,29.319104,40.336879]\n",
    "\n",
    "\n",
    "## example:\n",
    "# areaname = 'Istanbul'\n",
    "# bbox = [28.966667,40.966667,29.216667,41.116667]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed7738",
   "metadata": {},
   "source": [
    "### Kütüphanelerin yüklenmesi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0b84a3",
   "metadata": {},
   "source": [
    "Bu not defterinde aşağıdaki Python kütüphanelerini kullanacağız:\n",
    "\n",
    "- [pandas](https://pandas.pydata.org/) - Tablo şeklindeki verilerle çalışmak için temel bir veri işleme ve analiz kütüphanesidir.\n",
    "- [geopandas](https://geopandas.org/) - Coğrafi verileri analiz etmek ve görselleştirmek için pandas'ı genişleten bir kütüphane.\n",
    "- [psycopg2](https://www.psycopg.org/docs/) - PostgreSQL veritabanları ile bağlantı kurmak ve SQL sorguları çalıştırmak için kullanılan bir veritabanı adaptörüdür.\n",
    "- [plotly](https://plotly.com/python/) - Etkileşimli grafikler, haritalar ve görselleştirmeler oluşturmak için güçlü bir kütüphane.\n",
    "- [requests](https://docs.python-requests.org/en/latest/) - HTTP istekleri göndermek ve API'lerden veri almak için kullanılan basit ve etkili bir kütüphane.\n",
    "- [osmnx](https://osmnx.readthedocs.io/en/stable/) - OpenStreetMap verilerini indirip, analiz edip, görselleştirmek için kullanılan bir kütüphane.\n",
    "\n",
    "Bu kütüphaneler, coğrafi ve sayısal verilerin indirilmesi, işlenmesi, analiz edilmesi ve görselleştirilmesini sağlar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6424548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for downloading data and managing files\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# analysis\n",
    "    # data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "    # density and geometry\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.spatial import Voronoi\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from scipy.spatial import cKDTree\n",
    "    # clustering and scaling\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "    # clustering evaluation\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# working with geospatial data (shapefile, GeoJSON, etc.)\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box, Point, Polygon, MultiPolygon, MultiPoint, LineString\n",
    "\n",
    "# for interactive graphs and map-based visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Circle\n",
    "from matplotlib.collections import LineCollection\n",
    "import contextily as ctx\n",
    "import seaborn as sns \n",
    "\n",
    "# for downloading, analyzing and visualizing OSM data\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "# for raster data\n",
    "import rasterio\n",
    "from rasterio.warp import transform_bounds, reproject, Resampling, calculate_default_transform\n",
    "from rasterio.features import rasterize\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# for warnings\n",
    "import warnings\n",
    "\n",
    "# fancy progress bar\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c2c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to show warnings :)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3770d1d",
   "metadata": {},
   "source": [
    "### Dosya yapısının oluşturulması\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa744021",
   "metadata": {},
   "source": [
    "Analiz sürecinde verilerin ve çıktıların düzenli bir şekilde saklanabilmesi için klasörleme sistemi oluşturuyoruz. Böylece veri dosyaları ve görseller gibi farklı içerikler kolayca yönetilebilir ve tekrar erişilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17e3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the folder for the workflow\n",
    "workflow_folder = 'ORDERS_SERVICE_AREA'\n",
    "\n",
    "# check if the workflow folder exists, if not, create it\n",
    "if not os.path.exists(workflow_folder):\n",
    "    os.makedirs(workflow_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509df9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directories for data and plots within the previously defined workflow folder\n",
    "data_dir = os.path.join(workflow_folder, f'data_{areaname}')\n",
    "plot_dir = os.path.join(workflow_folder, f'plots_{areaname}')\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f246c2f2",
   "metadata": {},
   "source": [
    "### Çalışma alanına ait coğrafi verilerin temini ve görüntülenmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509ca776",
   "metadata": {},
   "source": [
    "#### Vektörel Veriler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0fdca3",
   "metadata": {},
   "source": [
    "Yol verileri için OSMnx kütüphanesi aracılığılıyla OpenStreetMap'ten ve idari sınırlar için Bursa Açık Veri Platformu'nu kullanıyoruz. Verilerin güncelliğini korumak maksatıyla bir defaya mahsus webten temin edilmesi gerekmektedir ve bu işlem ortalama bir internet bağlantısı ile bir dakikada gerçekleşmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc761e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bounding box to polygon\n",
    "def create_bbox_polygon(bbox):\n",
    "    return box(*bbox)\n",
    "\n",
    "# download road network or if it's downloaded before, load from file (it takes a minute to download with an average network speed)\n",
    "def get_road_network(bbox, filepath):\n",
    "    if os.path.exists(filepath):\n",
    "        print(\"Yol ağı dosyadan yükleniyor\")\n",
    "        return ox.load_graphml(filepath)\n",
    "    else:\n",
    "        print(\"Yol ağı indiriliyor\")\n",
    "        polygon = create_bbox_polygon(bbox)\n",
    "        G = ox.graph_from_polygon(polygon, network_type='drive')\n",
    "        ox.save_graphml(G, filepath)\n",
    "        return G\n",
    "\n",
    "def convert_road_network_to_meters(roads):\n",
    "    roads_3857 = ox.project_graph(roads, to_crs='EPSG:3857')\n",
    "    return roads_3857\n",
    "\n",
    "# download admin boundaries by area name or if it's downloaded before, load from file\n",
    "def get_bursa_admin_data(districts_filepath, nbh_filepath):\n",
    "    districts_gdf = gpd.GeoDataFrame()\n",
    "    nbh_gdf = gpd.GeoDataFrame()\n",
    "    \n",
    "    # ilce\n",
    "    if os.path.exists(districts_filepath):\n",
    "        print(\"İlçe verileri dosyadan yükleniyor\")\n",
    "        districts_gdf = gpd.read_file(districts_filepath)\n",
    "    else:\n",
    "        print(\"İlçe verileri Bursa Açık Veri Portalından indiriliyor\")\n",
    "        \n",
    "        try:\n",
    "            # ilce (bursa acik veri portalindan)\n",
    "            url = \"https://bapi.bursa.bel.tr/apigateway/bbbAcikVeri_Cbs/ILCE\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            districts_gdf = gpd.GeoDataFrame.from_features(data['features'])\n",
    "            districts_gdf.set_crs('EPSG:4326', inplace=True)\n",
    "            columns_to_keep = ['AD', 'ID', 'MERKEZILCEMI', 'KIMLIKNO', 'geometry']\n",
    "            existing_columns = [col for col in columns_to_keep if col in districts_gdf.columns]\n",
    "            districts_gdf = districts_gdf[existing_columns]\n",
    "            \n",
    "            # renaming columns for consistency\n",
    "            districts_gdf = districts_gdf.rename(columns={'AD': 'name', 'ID': 'guid', 'MERKEZILCEMI': 'center_district', 'KIMLIKNO': 'id'})\n",
    "            \n",
    "            # removing rows with null geometry\n",
    "            districts_gdf = districts_gdf.dropna(subset=['geometry'])\n",
    "            \n",
    "            # saving to file\n",
    "            districts_gdf.to_file(districts_filepath)\n",
    "            print(f\"İlçe verileri başarıyla indirildi: {len(districts_gdf)} öğe\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Hata: İlçe verileri alınamadı: {e}\")\n",
    "            districts_gdf = gpd.GeoDataFrame()\n",
    "    \n",
    "    # mahalle\n",
    "    if os.path.exists(nbh_filepath):\n",
    "        print(\"Mahalle verileri dosyadan yükleniyor\")\n",
    "        nbh_gdf = gpd.read_file(nbh_filepath)\n",
    "    else:\n",
    "        print(\"Mahalle verileri Bursa Açık Veri Portalından indiriliyor\")\n",
    "        \n",
    "        try:\n",
    "            # mahalle (bursa acik veri portalindan)\n",
    "            url = \"https://bapi.bursa.bel.tr/apigateway/bbbAcikVeri_Cbs/Mahalle\"\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            nbh_gdf = gpd.GeoDataFrame.from_features(data['features'])\n",
    "            nbh_gdf.set_crs('EPSG:4326', inplace=True)\n",
    "            \n",
    "            # removing unnecessary columns\n",
    "            columns_to_keep = ['AD', 'ID', 'ILCEID', 'KIMLIKNO', 'geometry']\n",
    "            existing_columns = [col for col in columns_to_keep if col in nbh_gdf.columns]\n",
    "            nbh_gdf = nbh_gdf[existing_columns]\n",
    "            \n",
    "            # renaming columns for consistency\n",
    "            nbh_gdf = nbh_gdf.rename(columns={'AD': 'name', 'ID': 'guid', 'ILCEID': 'district_id', 'KIMLIKNO': 'id'})\n",
    "            \n",
    "            # removing rows with null geometry\n",
    "            nbh_gdf = nbh_gdf.dropna(subset=['geometry'])\n",
    "            \n",
    "            nbh_gdf.to_file(nbh_filepath)\n",
    "            print(f\"Mahalle verileri başarıyla indirildi: {len(nbh_gdf)} öğe\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Hata: Mahalle verileri alınamadı: {e}\")\n",
    "            nbh_gdf = gpd.GeoDataFrame()\n",
    "    \n",
    "    return districts_gdf, nbh_gdf\n",
    "        \n",
    "# sınırların ve yolların görselleştirilmesi\n",
    "def plot_boundaries(districts, neighbourhoods, roads, area_name, bbox):\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    use_crs = 'EPSG:3857'\n",
    "\n",
    "    # veri çizimi v2\n",
    "    if not districts.empty:\n",
    "        districts.to_crs(use_crs).plot(ax=ax, facecolor='none', edgecolor='black', linewidth=1, alpha=0.7)\n",
    "    \n",
    "    if not neighbourhoods.empty:\n",
    "        neighbourhoods.to_crs(use_crs).plot(ax=ax, color='#FAD7A0', edgecolor='black', alpha=0.05)\n",
    "    \n",
    "    if roads is not None:\n",
    "        edges = ox.graph_to_gdfs(roads, nodes=False, edges=True).to_crs(use_crs)\n",
    "        road_colors = {\n",
    "            'motorway': ('#E74C3C', 1.5),\n",
    "            'trunk':    ('#D35400', 1.5),\n",
    "            'primary':  ('#F1C40F', 1.5),\n",
    "            'secondary':('#27AE60', 1),\n",
    "            'tertiary': ('#2980B9', 1)\n",
    "        }\n",
    "        for rt, (color, lw) in road_colors.items():\n",
    "            mask = edges['highway'].apply(lambda hw: rt in hw if isinstance(hw, list) else hw == rt)\n",
    "            edges[mask].plot(ax=ax, color=color, linewidth=lw, alpha=0.8)\n",
    "\n",
    "    # alan sınırları\n",
    "    bbox_gdf = gpd.GeoDataFrame(geometry=[box(*bbox)], crs='EPSG:4326').to_crs(use_crs)\n",
    "    bbox_gdf.head()\n",
    "    minx, miny, maxx, maxy = bbox_gdf.total_bounds\n",
    "    buffer = max((maxx - minx), (maxy - miny)) * 0.1\n",
    "    ax.set_xlim(bbox_gdf.total_bounds[0] - 5000, bbox_gdf.total_bounds[2] + 5000)\n",
    "    ax.set_ylim(bbox_gdf.total_bounds[1] - 5000, bbox_gdf.total_bounds[3] + 5000)\n",
    "\n",
    "    # basemap\n",
    "    zoom = 12 if max(bbox[2] - bbox[0], bbox[3] - bbox[1]) < 0.1 else 10\n",
    "    try:\n",
    "        ctx.add_basemap(ax, zoom=zoom, source=ctx.providers.CartoDB.Positron)\n",
    "    except:\n",
    "        print(\"Basemap yüklenemedi\")\n",
    "\n",
    "    # görsel ayarlar\n",
    "    ax.set_xlabel(\"X (metre)\")\n",
    "    ax.set_ylabel(\"Y (metre)\")\n",
    "    ax.set_title(f\"OpenStreetMap {area_name} ve Bursa Açık Veri Portalı verileri\", fontsize=15, fontweight='bold', color='#2C3E50')\n",
    "    \n",
    "    # legend v2\n",
    "    legend_elements = [\n",
    "        mlines.Line2D([], [], color='black', lw=2, label='İlçe Sınırı'),\n",
    "        mlines.Line2D([], [], color='black', lw=1, alpha=0.3, label='Mahalle Sınırı'),\n",
    "        mlines.Line2D([], [], color='#E74C3C', lw=2, label='Otoyol'),\n",
    "        mlines.Line2D([], [], color='#D35400', lw=1.5, label='Ekspres Yol'),\n",
    "        mlines.Line2D([], [], color='#F1C40F', lw=1.2, label='Ana Yol'),\n",
    "        mlines.Line2D([], [], color='#27AE60', lw=1, label='İkincil Yol'),\n",
    "        mlines.Line2D([], [], color='#2980B9', lw=1, label='Tali Yol'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right', fontsize=8, frameon=True, title=\"Lejant\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(plot_dir, f'{area_name}_osm_boundaries.png'), dpi=600, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "# main workflow\n",
    "def analyze_area(bbox, area_name, data_folder=data_dir, plots_folder=plot_dir):\n",
    "    \n",
    "    os.makedirs(data_folder, exist_ok=True)\n",
    "    os.makedirs(plots_folder, exist_ok=True)\n",
    "    \n",
    "    # setting file paths\n",
    "    road_file = os.path.join(data_folder, f'{area_name}_roads.graphml')\n",
    "    districts_file = os.path.join(data_folder, f'{area_name}_districts.geojson')\n",
    "    nbh_file = os.path.join(data_folder, f'{area_name}_neighbourhoods.geojson')\n",
    "    \n",
    "    print(f\"{area_name} bölgesi için veri yükleniyor\")\n",
    "    print(\"-\" * 10)\n",
    "    \n",
    "    # yollar (bbox ile kapsam alanı artıyor)\n",
    "    roads = get_road_network(bbox, road_file)\n",
    "    \n",
    "    # bolge idari sinirlar\n",
    "    districts , neighbourhoods = get_bursa_admin_data(districts_file, nbh_file)\n",
    "    \n",
    "    print(f\"Veri Özeti:\")\n",
    "    print(f\"- Yollar: {len(roads.nodes)} düğüm, {len(roads.edges)} kenar\")\n",
    "    print(f\"- İlçeler: {len(districts)} öğe\")\n",
    "    print(f\"- Mahalleler: {len(neighbourhoods)} öğe\")\n",
    "    \n",
    "    # data vis\n",
    "    plot_boundaries(districts, neighbourhoods, roads, area_name, bbox)\n",
    "    \n",
    "    return roads, districts, neighbourhoods\n",
    "\n",
    "# sample usage\n",
    "# roads, districts, neighbourhoods = analyze_area(bbox, area_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "roads, districts, neighbourhoods = analyze_area(bbox, areaname)\n",
    "roads_3857 = convert_road_network_to_meters(roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269e9df",
   "metadata": {},
   "source": [
    "#### Raster Veri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cc635",
   "metadata": {},
   "source": [
    "Alos Palsar açıklama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efc652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebookta olduğundan mı bilmiyorum ama proj ortamlarını temizlemezsem çalışmıyor \n",
    "# https://rasterio.readthedocs.io/en/stable/faq.html#why-can-t-rasterio-find-proj-db-rasterio-versions-1-2-0\n",
    "# [sonra bak]\n",
    "[os.environ.pop(k, None) for k in ['PROJ_LIB', 'PROJ_DATA']]\n",
    "\n",
    "with rasterio.open(r\"..\\data\\cropped_alos_palsar.tif\") as src:\n",
    "    # reading the data\n",
    "    data_orig = src.read(1)\n",
    "    bounds = src.bounds\n",
    "\n",
    "    # masking the raster to remove no-data values that are created by masking process\n",
    "    mask_orig = data_orig != src.nodata if src.nodata else np.ones_like(data_orig, dtype=bool)\n",
    "    valid_orig = data_orig[mask_orig]\n",
    "    vmin, vmax = np.percentile(valid_orig, [2, 98])\n",
    "\n",
    "    # reproject to web mercator to overlay with basemap\n",
    "    target_crs = 'EPSG:3857'\n",
    "\n",
    "    # plot variables\n",
    "    data_plot = data_orig;    mask_plot = mask_orig;    bounds_plot = bounds;    crs_plot = src.crs.to_string();    pixel_width = src.transform.a;    pixel_height = -src.transform.e\n",
    "\n",
    "    # source: https://rasterio.readthedocs.io/en/latest/topics/reproject.html\n",
    "    if src.crs.to_string() != target_crs:\n",
    "        bounds_plot = transform_bounds(src.crs, target_crs, *bounds)\n",
    "        dst_transform, w, h = calculate_default_transform(src.crs, target_crs, src.width, src.height, *src.bounds)\n",
    "        dst_array = np.empty((h, w), dtype=np.float32)\n",
    "        reproject(\n",
    "            source=data_orig,\n",
    "            destination=dst_array,\n",
    "            src_transform=src.transform,\n",
    "            src_crs=src.crs,\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=target_crs,\n",
    "            resampling=Resampling.nearest\n",
    "        )\n",
    "        data_plot = dst_array\n",
    "        mask_plot = dst_array != src.nodata if src.nodata else np.ones_like(dst_array, dtype=bool)\n",
    "        valid_plot = data_plot[mask_plot]\n",
    "        vmin, vmax = np.percentile(valid_plot, [2, 98])\n",
    "        crs_plot = target_crs\n",
    "        pixel_width = dst_transform.a\n",
    "        pixel_height = -dst_transform.e  # usually negative, so take abs\n",
    "\n",
    "    # plot settings\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    display_data = np.ma.masked_where((~mask_plot) | (data_plot <= np.percentile(data_plot[mask_plot], 1)), data_plot)\n",
    "    img = ax.imshow(display_data, extent=[bounds_plot[0], bounds_plot[2], bounds_plot[1], bounds_plot[3]], origin='upper', cmap='gray', vmin=vmin, vmax=vmax)\n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=crs_plot, alpha=0.5)\n",
    "    cbar = plt.colorbar(img, ax=ax, fraction=0.03, pad=0.04)\n",
    "    cbar.set_label(\"ALOS PALSAR HH Backscatter (dB)\")\n",
    "    plt.title(\"ALOS PALSAR HH Backscatter\")\n",
    "    plt.axis('on')\n",
    "    plt.show()\n",
    "\n",
    "# only using the valid pixels\n",
    "raster_values = data_orig[mask_orig].flatten()\n",
    "df_raster = pd.DataFrame({'value': raster_values})\n",
    "\n",
    "print(f\"Piksel boyutu: {pixel_width:.2f} x {pixel_height:.2f} mt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba87ff39",
   "metadata": {},
   "source": [
    "### Çalışma alanına ait demografik verilerin temini\n",
    "\n",
    "31 Aralık 2024 tarihli Adrese Dayalı Nüfus Kayıt Sistemi (ADNKS) verisi, TÜİK web sitesinden temin edilmiştir.\n",
    "\n",
    "Veri, mahalle düzeyinde toplam nüfus, cinsiyet ve yaş grubu gibi demografik bilgileri içermektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bd4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuik doesn't allow to download data with web requests so we have to use local file\n",
    "file_path = '../data/bursa_nbh_pop.xls'\n",
    "\n",
    "try:\n",
    "    bursa_neighbourhood = pd.read_excel(file_path)\n",
    "    print('Adrese Dayalı Nüfus Kayıt Sistemi verisinden mahalle nüfus verisi okundu.')\n",
    "except Exception as e:\n",
    "    print(f'CSV dosyası okunamadı: {e}')\n",
    "    \n",
    "file_path = '../data/bursa_district_age.xls'\n",
    "\n",
    "try:\n",
    "    bursa_district_age = pd.read_excel(file_path)\n",
    "    print('Adrese Dayalı Nüfus Kayıt Sistemi verisinden ilçe yaş verisi okundu.')\n",
    "except Exception as e:\n",
    "    print(f'CSV dosyası okunamadı: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf8b99",
   "metadata": {},
   "source": [
    "### Verinin çalışma alanına uygun hale getirilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d48fc",
   "metadata": {},
   "source": [
    "TÜİK verilerinin ham formatındaki başlık satırları ve gereksiz sütunlar nedeniyle veriyi temizledikten sonra, mahalle ve ilçe bilgilerini içeren metinleri ayrıştırarak il, ilçe, belediye, mahalle gibi coğrafi bileşenleri ayrı sütunlara çıkarıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad5a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the column names\n",
    "bursa_nbh_fixed = bursa_neighbourhood.copy()\n",
    "bursa_nbh_fixed.columns = bursa_nbh_fixed.iloc[3]\n",
    "bursa_nbh_fixed = bursa_nbh_fixed.drop(index=range(0, 5)).reset_index(drop=True)\n",
    "bursa_nbh_fixed = bursa_nbh_fixed.iloc[:, -2:]\n",
    "bursa_nbh_fixed.columns = ['mahalle', 'nufus']\n",
    "\n",
    "# parse 'mahalle' column: city(district/municipality/neighbourhood)-id\n",
    "def parse_mahalle(val):\n",
    "    main, id = val.rsplit('-', 1)\n",
    "    city, rest = main.split('(', 1)\n",
    "    rest = rest.rstrip(')')\n",
    "    parts = rest.split('/')\n",
    "    district, municipality, neighbourhood = parts\n",
    "    return pd.Series([city.strip(), district, municipality, neighbourhood, id])\n",
    "\n",
    "parsed = bursa_nbh_fixed['mahalle'].apply(parse_mahalle)\n",
    "bursa_nbh_fixed = pd.concat([parsed, bursa_nbh_fixed['nufus']], axis=1)\n",
    "bursa_nbh_fixed.columns = ['city', 'district', 'municipality', 'neighbourhood', 'id', 'nufus']\n",
    "\n",
    "bursa_district_age_fixed = bursa_district_age.copy()\n",
    "bursa_district_age_fixed = bursa_district_age_fixed.drop(bursa_district_age_fixed.columns[0], axis=1)\n",
    "bursa_district_age_fixed.columns = bursa_district_age_fixed.iloc[1]\n",
    "bursa_district_age_fixed = bursa_district_age_fixed.drop(index=[0,1,2,3]).reset_index(drop=True)\n",
    "bursa_district_age_fixed = bursa_district_age_fixed.rename(columns={bursa_district_age_fixed.columns[0]: 'ilce'})\n",
    "\n",
    "# parse 'ilce' column: city(district)-id\n",
    "def parse_ilce(val):\n",
    "    main, id = val.rsplit('-', 1)\n",
    "    city, district = main.split('(')\n",
    "    district = district.rstrip(')')\n",
    "    return pd.Series([city.strip(), district.strip(), id.strip()])\n",
    "\n",
    "parsed_district = bursa_district_age_fixed['ilce'].apply(parse_ilce)\n",
    "parsed_district.columns = ['city', 'district', 'id']\n",
    "bursa_district_age_fixed = pd.concat([parsed_district, bursa_district_age_fixed], axis=1)\n",
    "bursa_district_age_fixed = bursa_district_age_fixed.drop(columns=['ilce'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b004d37",
   "metadata": {},
   "source": [
    "### Sipariş ve Depo Verilerinin Temini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d04b40b",
   "metadata": {},
   "source": [
    "Açıklama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ee9db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, name):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f'{name} verisi okundu.')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'{name} verisi okunamadı: {e}')\n",
    "        return None\n",
    "\n",
    "def find_coords(df):\n",
    "    cols = {col.lower(): col for col in df.columns}\n",
    "    try:\n",
    "        return cols['longitude'], cols['latitude']\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"{df} verisinde 'longitude' ve/veya 'latitude' kolonları bulunamadı.\")\n",
    "\n",
    "order_df = load_data('../data/order.csv', 'Sipariş')\n",
    "wh_df = load_data('../data/warehouse.csv', 'Depo')\n",
    "\n",
    "if order_df is not None and wh_df is not None:\n",
    "    s_long, s_lat = find_coords(order_df)\n",
    "    w_long, w_lat = find_coords(wh_df)\n",
    "\n",
    "    order_gdf = gpd.GeoDataFrame(order_df, geometry=gpd.points_from_xy(order_df[s_long], order_df[s_lat]), crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "    wh_gdf = gpd.GeoDataFrame(wh_df, geometry=gpd.points_from_xy(wh_df[w_long], wh_df[w_lat]), crs=\"EPSG:4326\").to_crs(epsg=3857)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    order_gdf.plot(ax=ax, markersize=5, color='blue', label='Siparişler', alpha=0.1)\n",
    "    wh_gdf.plot(ax=ax, markersize=50, color='red', marker='s', label='Depolar', edgecolor='white', linewidth=1)\n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "    # 3857 projeksiyonu için eksen etiketlerini kaldır\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    plt.legend()\n",
    "    plt.title('Sipariş ve Depo Noktaları')\n",
    "    plt.savefig(plot_dir + '/' + areaname + '_orders_warehouses.png')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('veri okunamadı')\n",
    "    order_gdf = None\n",
    "    wh_gdf = None \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5fe18",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5427e148",
   "metadata": {},
   "source": [
    "## Sipariş Verisinin Mekansal Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b261cf1a",
   "metadata": {},
   "source": [
    "Açıklama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ca5b3",
   "metadata": {},
   "source": [
    "### Isı Haritası"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed37912",
   "metadata": {},
   "source": [
    "Açıklama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7804c419",
   "metadata": {},
   "source": [
    "#### Sipariş bazında"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e4aa9b",
   "metadata": {},
   "source": [
    "Açıklama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c6b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to 3857 for analysis\n",
    "order_3857 = order_gdf.to_crs(epsg=3857)\n",
    "wh_3857 = wh_gdf.to_crs(epsg=3857)\n",
    "x, y = order_3857.geometry.x.values, order_3857.geometry.y.values\n",
    "w_x, w_y = wh_3857.geometry.x.values, wh_3857.geometry.y.values\n",
    "\n",
    "revenue = order_gdf['revenue'].values\n",
    "basket = order_gdf['basket_value'].values\n",
    "delivery = order_gdf['delivery duration'].values\n",
    "\n",
    "districts_3857 = districts.to_crs(epsg=3857)\n",
    "nbh_3857 = neighbourhoods.to_crs(epsg=3857)\n",
    "\n",
    "maps = [\n",
    "    ('Sipariş Yoğunluğu', None, 'YlOrRd'),\n",
    "    ('Toplam Gelir (₺)', revenue, 'viridis'),\n",
    "    ('Ortalama Sepet Değeri (₺)', basket, 'plasma'),\n",
    "    ('Ortalama Teslimat Süresi (dk)', delivery, 'RdYlBu_r')\n",
    "]\n",
    "labels = ['(a)', '(b)', '(c)', '(d)']\n",
    "filenames = ['order_density', 'revenue_distribution', 'basket_value', 'delivery_duration']\n",
    "\n",
    "def plot_hex(ax, data, cmap, title, label, single=False):\n",
    "    districts_3857.boundary.plot(ax=ax, linewidth=1, edgecolor='grey', alpha=0.7, zorder=7)\n",
    "    nbh_3857.boundary.plot(ax=ax, linewidth=0.5, edgecolor='lightgrey', alpha=0.5, zorder=6)\n",
    "    # hexbins (need a fix)\n",
    "    hb = ax.hexbin(x, y, C=data, gridsize=40, cmap=cmap, alpha=0.8, zorder=3)\n",
    "    plt.colorbar(hb, ax=ax, shrink=0.8)\n",
    "    # warehouse and buffer\n",
    "    wh_handles = []\n",
    "    buffer_handles = []\n",
    "    for wx, wy in zip(w_x, w_y):\n",
    "        # warehouse\n",
    "        wh = ax.scatter(wx, wy, s=80, c='red', marker='s', edgecolor='black', linewidth=1.5, zorder=8, label='Depo')\n",
    "        # buffer\n",
    "        buf = ax.add_patch(plt.Circle((wx, wy), 5000, fill=False, color='red', linestyle='--', alpha=0.5, linewidth=2, zorder=5, label='Etki Alanı (5km)'))\n",
    "        wh_handles.append(wh)\n",
    "        buffer_handles.append(buf)\n",
    "    #zoom into boundaries\n",
    "    ax.set_xlim(order_3857.total_bounds[0] - 5000, order_3857.total_bounds[2] + 5000)\n",
    "    ax.set_ylim(order_3857.total_bounds[1] - 5000, order_3857.total_bounds[3] + 5000)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(f'{label} {title}', fontsize=11, weight='bold')\n",
    "    ax.set_xlabel('Kuzey (×10⁶ m)', fontsize=9)\n",
    "    ax.set_ylabel('Doğu (×10⁶ m)', fontsize=9)\n",
    "    ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda val, p: f'{val/1e6:.2f}'))\n",
    "    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda val, p: f'{val/1e6:.2f}'))\n",
    "    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
    "    ax.axhline(y=0, color='black', linewidth=0.5)\n",
    "    ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "\n",
    "    # custom legend\n",
    "    wh_legend = mlines.Line2D([], [], color='red', marker='s', linestyle='None', markersize=10, markeredgecolor='black', label='Depo')\n",
    "    buffer_legend = mpatches.Patch(facecolor='none', edgecolor='red', linestyle='--', linewidth=1, alpha=0.5, label='Etki Alanı (5km)')\n",
    "    ax.legend(handles=[wh_legend, buffer_legend], loc='upper right', fontsize=9, frameon=True)\n",
    "\n",
    "    if single:\n",
    "        plt.tight_layout()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle(f'{areaname.capitalize()} Bölgesi Teslimat Analizi (Genel Bakış)', fontsize=14, weight='bold')\n",
    "\n",
    "# saving plots\n",
    "for i, (title, data, cmap) in enumerate(maps):\n",
    "    ax = axes[i//2, i%2]\n",
    "    plot_hex(ax, data, cmap, title, labels[i])\n",
    "    fig_single, ax_single = plt.subplots(figsize=(12, 9))\n",
    "    plot_hex(ax_single, data, cmap, title, labels[i], single=True)\n",
    "    fig_single.savefig(f\"{plot_dir}/{areaname}_{filenames[i]}.png\", dpi=600)\n",
    "    plt.close(fig_single)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd0488c",
   "metadata": {},
   "source": [
    "#### Mahalle bazında"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2143517b",
   "metadata": {},
   "source": [
    "Açıklama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49904955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbh_based_analysis(order_gdf, nbh_gdf, wh_gdf):\n",
    "    order_3857 = order_gdf.to_crs(epsg=3857)\n",
    "    nbh_3857 = nbh_gdf.to_crs(epsg=3857)\n",
    "    wh_3857 = wh_gdf.to_crs(epsg=3857)\n",
    "    # spatial join to get mahalle-based statistics\n",
    "    order_neighbourhood = gpd.sjoin(order_3857, nbh_3857, how='left', predicate='within')\n",
    "    stats = order_neighbourhood.groupby('index_right').agg(\n",
    "        revenue_sum=('revenue', 'sum'),\n",
    "        revenue_mean=('revenue', 'mean'),\n",
    "        revenue_count=('revenue', 'count'),\n",
    "        basket_value_mean=('basket_value', 'mean'),\n",
    "        basket_value_std=('basket_value', 'std'),\n",
    "        delivery_duration_mean=('delivery duration', 'mean'),\n",
    "        delivery_duration_std=('delivery duration', 'std')\n",
    "    ).round(2).rename(columns={\n",
    "        'revenue_sum': 'toplam_gelir',\n",
    "        'revenue_mean': 'ortalama_gelir',\n",
    "        'revenue_count': 'siparis_sayisi',\n",
    "        'basket_value_mean': 'ortalama_sepet',\n",
    "        'basket_value_std': 'sepet_std',\n",
    "        'delivery_duration_mean': 'ortalama_teslimat',\n",
    "        'delivery_duration_std': 'teslimat_std'\n",
    "    })\n",
    "    nbh_analysis = nbh_3857.reset_index().merge(stats, left_on='index', right_index=True, how='left')\n",
    "    cols = ['toplam_gelir', 'ortalama_gelir', 'siparis_sayisi', 'ortalama_sepet', 'sepet_std', 'ortalama_teslimat', 'teslimat_std']\n",
    "    nbh_analysis[cols] = nbh_analysis[cols].fillna(0)\n",
    "    return nbh_analysis, wh_3857\n",
    "\n",
    "def plot_neighbourhood(nbh_analysis, wh_3857, metrics, bounds, plot_dir, areaname=\"bolge\"):\n",
    "    os.makedirs(plot_dir, exist_ok=True)\n",
    "    for metric, (label, title, filename) in metrics.items():\n",
    "        fig, ax = plt.subplots(figsize=(12, 9))\n",
    "        nbh_analysis.plot(column=metric, ax=ax, legend=True, cmap='viridis', edgecolor='white', linewidth=0.5,\n",
    "                            legend_kwds={'shrink': 0.8, 'aspect': 20}, alpha=0.75, zorder=3)\n",
    "        wh_3857.plot(ax=ax, color='red', marker='s', markersize=150, edgecolor='black', linewidth=1.5, zorder=4)\n",
    "        for _, row in wh_3857.iterrows():\n",
    "            ax.add_patch(Circle((row.geometry.x, row.geometry.y), 5000, fill=False, color='red', linestyle='--', alpha=0.6, linewidth=2, zorder=2))\n",
    "        ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, alpha=0.5)\n",
    "        ax.set_title(f'{label} {title}', fontsize=13, weight='bold')\n",
    "        ax.set_xlabel('Kuzey (×10⁶ m)', fontsize=10)\n",
    "        ax.set_ylabel('Doğu (×10⁶ m)', fontsize=10)\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda val, p: f'{val / 1e6:.2f}'))\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda val, p: f'{val / 1e6:.2f}'))\n",
    "        ax.set_xlim(bounds[0] - 5000, bounds[2] + 5000)\n",
    "        ax.set_ylim(bounds[1] - 5000, bounds[3] + 5000)\n",
    "        ax.set_aspect('equal')\n",
    "        depo_leg = mlines.Line2D([], [], color='red', marker='s', linestyle='None', markersize=10, markeredgecolor='black', label='Depo')\n",
    "        buffer_leg = mpatches.Patch(facecolor='none', edgecolor='red', linestyle='--', linewidth=2, alpha=0.6, label='Etki Alanı (5km)')\n",
    "        ax.legend(handles=[depo_leg, buffer_leg], loc='upper right', fontsize=9)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(plot_dir, f\"{areaname}_nbh_{filename}.png\"), dpi=300, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "    # 2x2 genel görünüm\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle(f'{areaname.capitalize()} Bölgesi Mahalle Bazlı Teslimat Analizi (Genel Bakış)', fontsize=16, weight='bold')\n",
    "    for ax, (metric, (label, title, _)) in zip(axes.flat, metrics.items()):\n",
    "        nbh_analysis.plot(column=metric, ax=ax, legend=True, cmap='viridis', edgecolor='white', linewidth=0.5,\n",
    "                            legend_kwds={'shrink': 0.8, 'aspect': 20}, alpha=0.75, zorder=3)\n",
    "        wh_3857.plot(ax=ax, color='red', marker='s', markersize=150, edgecolor='black', linewidth=1.5, zorder=4)\n",
    "        for _, row in wh_3857.iterrows():\n",
    "            ax.add_patch(Circle((row.geometry.x, row.geometry.y), 5000, fill=False, color='red', linestyle='--', alpha=0.6, linewidth=2, zorder=2))\n",
    "        ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, alpha=0.5)\n",
    "        ax.set_title(f'{label} {title}', fontsize=12, weight='bold')\n",
    "        ax.set_xlabel('Kuzey (×10⁶ m)', fontsize=9)\n",
    "        ax.set_ylabel('Doğu (×10⁶ m)', fontsize=9)\n",
    "        ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda val, p: f'{val / 1e6:.2f}'))\n",
    "        ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda val, p: f'{val / 1e6:.2f}'))\n",
    "        ax.set_xlim(bounds[0] - 5000, bounds[2] + 5000)\n",
    "        ax.set_ylim(bounds[1] - 5000, bounds[3] + 5000)\n",
    "        ax.set_aspect('equal')\n",
    "        depo_leg = mlines.Line2D([], [], color='red', marker='s', linestyle='None', markersize=10, markeredgecolor='black', label='Depo')\n",
    "        buffer_leg = mpatches.Patch(facecolor='none', edgecolor='red', linestyle='--', linewidth=2, alpha=0.6, label='Etki Alanı (5km)')\n",
    "        ax.legend(handles=[depo_leg, buffer_leg], loc='upper right', fontsize=8)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "    plt.savefig(os.path.join(plot_dir, f\"{areaname}_nbh_analysis_grid.png\"), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "nbh_analysis, wh_3857 = nbh_based_analysis(order_gdf, neighbourhoods, wh_gdf)\n",
    "metrics = {\n",
    "    'siparis_sayisi': ('(a)', 'Sipariş Yoğunluğu', 'order_density'),\n",
    "    'toplam_gelir': ('(b)', 'Toplam Gelir Dağılımı (₺)', 'revenue_distribution'),\n",
    "    'ortalama_sepet': ('(c)', 'Ortalama Sepet Değeri (₺)', 'basket_value'),\n",
    "    'ortalama_teslimat': ('(d)', 'Ortalama Teslimat Süresi (dakika)', 'delivery_duration')\n",
    "}\n",
    "bounds = order_gdf.to_crs(epsg=3857).total_bounds\n",
    "plot_neighbourhood(nbh_analysis, wh_3857, metrics, bounds, plot_dir=plot_dir, areaname=areaname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dae522",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52522ece",
   "metadata": {},
   "source": [
    "## Optimum Servis Alanlarının Tasarlanması"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39932b44",
   "metadata": {},
   "source": [
    "Açıklama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e658db",
   "metadata": {},
   "source": [
    "### Sipariş Verisinin Zenginleştirilmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9ae08",
   "metadata": {},
   "source": [
    "#### Mahalle ve İlçe Verilerinin Eşleştirilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a874e",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_order_3857 = gpd.sjoin(order_3857, nbh_3857, how='left', predicate='within')\n",
    "enhanced_order_3857 = enhanced_order_3857.drop(columns=['index_right'])\n",
    "enhanced_order_3857 = gpd.sjoin(enhanced_order_3857, districts_3857, how='left', predicate='within')\n",
    "# rename columns\n",
    "enhanced_order_3857.rename(columns={'name_left': 'neighbourhood', 'guid_left': 'neighbourhood_id', 'name_right': 'district', 'delivery duration': 'delivery_duration'}, inplace=True)\n",
    "# reorder columns\n",
    "enhanced_order_3857 = enhanced_order_3857[['fid', 'order_id', 'client_id', 'profit', 'revenue', 'delivery_duration', 'neighbourhood', 'district', 'neighbourhood_id', 'district_id', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef186af",
   "metadata": {},
   "source": [
    "#### En Yakın Depo Tespiti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da781e04",
   "metadata": {},
   "source": [
    "1. **Yol Grafiğinde En Yakın Düğümün Bulunması**\n",
    "   - Her sipariş ve depo noktası için, yol ağındaki en yakın düğüm (node) tespit edilir.\n",
    "2. **Depolar İçin Dijkstra Algoritması ile Kısa Yol Hesaplama**\n",
    "   - Her depo için, Dijkstra algoritması kullanılarak diğer tüm düğümlere (sipariş noktalarına) olan en kısa mesafe ve yol bilgisi hesaplanır.\n",
    "3. **Siparişler İçin En Yakın Depo Seçimi ve Süre Hesaplama**\n",
    "   - Her sipariş için, depolar arasından en kısa mesafeye sahip olan depo seçilir.\n",
    "   - Seçilen depo ile sipariş noktası arasındaki en kısa yolun tahmini seyahat süresi hesaplanır.\n",
    "   - Mesafe, süre ve ortalama hız bilgileri kaydedilir.\n",
    "4. **Sonuçların Birleştirilmesi**\n",
    "   - Tüm siparişler işlendiğinde, hesaplanan sonuçlar sipariş verisiyle birleştirilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a10a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# motorcycle speed profiles with respect to opernstreetmap road types\n",
    "COURIER_SPEED = {\n",
    "    'motorway': 90,    'trunk': 70,    'primary': 60,\n",
    "    'secondary': 50,    'tertiary': 40,    'residential': 30,\n",
    "    'living_street': 20,    'service': 25,    'unclassified': 35,\n",
    "    'default': 40\n",
    "}\n",
    "\n",
    "# nearest nodes (warehouse -> order)\n",
    "def get_nearest_nodes(gdf, graph):\n",
    "    coords = np.column_stack([gdf.geometry.x, gdf.geometry.y])\n",
    "    node_coords = np.array([[graph.nodes[n]['x'], graph.nodes[n]['y']] for n in graph.nodes()])\n",
    "    \n",
    "    tree = cKDTree(node_coords)\n",
    "    _, indices = tree.query(coords)\n",
    "    nodes = [list(graph.nodes())[i] for i in indices]\n",
    "    return nodes\n",
    "\n",
    "def find_closest_warehouse_with_time(orders_gdf, warehouses_gdf, road_graph):\n",
    "    # source: https://github.com/gboeing/osmnx/blob/main/osmnx/distance.py\n",
    "    order_nodes = get_nearest_nodes(orders_gdf, road_graph)\n",
    "    wh_nodes = get_nearest_nodes(warehouses_gdf, road_graph)\n",
    "    \n",
    "    results = []\n",
    "    failed_orders = 0\n",
    "    # it's very slow to process all orders at once, so we process them in batches\n",
    "    batch_size = 5000\n",
    "    \n",
    "    for batch_start in tqdm(range(0, len(order_nodes), batch_size), desc=\"paketler halinde hesaplanıyor\"):\n",
    "        batch_end = min(batch_start + batch_size, len(order_nodes))\n",
    "        \n",
    "        # run single-source dijkstra from each warehouse (distance-based)\n",
    "        wh_distances = {}\n",
    "        wh_paths = {}\n",
    "        \n",
    "        for wh_idx, wh_node in enumerate(wh_nodes):\n",
    "            try:\n",
    "                # Get both distances and paths\n",
    "                distances, paths = nx.single_source_dijkstra(\n",
    "                    road_graph, \n",
    "                    wh_node, \n",
    "                    cutoff=50000,  # 50km cutoff (it can be lowered)\n",
    "                    weight='length'\n",
    "                )\n",
    "                wh_distances[wh_idx] = distances\n",
    "                wh_paths[wh_idx] = paths\n",
    "            except Exception as e:\n",
    "                wh_distances[wh_idx] = {}\n",
    "                wh_paths[wh_idx] = {}\n",
    "        \n",
    "        # Find closest warehouse for each order in batch\n",
    "        for i in range(batch_start, batch_end):\n",
    "            order_node = order_nodes[i]\n",
    "            min_dist = float('inf')\n",
    "            closest_wh = None\n",
    "            best_path = None\n",
    "            \n",
    "            # Check distance from each warehouse to this order\n",
    "            for wh_idx, distances in wh_distances.items():\n",
    "                if order_node in distances:\n",
    "                    dist = distances[order_node]\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        closest_wh = wh_idx\n",
    "                        best_path = wh_paths[wh_idx].get(order_node, [])\n",
    "            \n",
    "            # Calculate travel time for the best path\n",
    "            travel_time = None\n",
    "            if best_path and len(best_path) > 1:\n",
    "                travel_time = get_courier_travel_time(road_graph, best_path)\n",
    "            \n",
    "            if closest_wh is None:\n",
    "                failed_orders += 1\n",
    "            \n",
    "            results.append({\n",
    "                'order_id': orders_gdf.iloc[i]['order_id'],\n",
    "                'closest_warehouse': warehouses_gdf.iloc[closest_wh]['Warehouse1'] if closest_wh is not None else None,\n",
    "                'distance_m': min_dist if min_dist != float('inf') else None,\n",
    "                'travel_time_min': travel_time,\n",
    "                'avg_speed_kmh': (min_dist/1000) / (travel_time/60) if travel_time and travel_time > 0 else None\n",
    "            })\n",
    "    \n",
    "    print(f\"seyahat mesafesi hesaplandı. hatalı işlemler: {failed_orders}\")\n",
    "    return results\n",
    "\n",
    "def get_courier_travel_time(road_graph, path):\n",
    "    total_time = 0\n",
    "    \n",
    "    for i in range(len(path) - 1):\n",
    "        edge_data = road_graph.get_edge_data(path[i], path[i+1])\n",
    "        if edge_data:\n",
    "            # Get first edge (in case of multiple edges)\n",
    "            edge = list(edge_data.values())[0]\n",
    "            \n",
    "            # get length\n",
    "            length = edge.get('length', 0)  # in meters\n",
    "            \n",
    "            # road type/highway classification\n",
    "            highway = edge.get('highway', 'default')\n",
    "            if isinstance(highway, list):\n",
    "                highway = highway[0]\n",
    "            \n",
    "            # speed limit or use default for road type\n",
    "            maxspeed = edge.get('maxspeed', None)\n",
    "            if maxspeed:\n",
    "                try:\n",
    "                    speed_kmh = int(maxspeed.split()[0]) if isinstance(maxspeed, str) else maxspeed\n",
    "                    # adding some realism to the speed limit and randomizing a little\n",
    "                    speed_kmh = min(speed_kmh * random.uniform(1.05, 1.15), COURIER_SPEED.get(highway, 40))\n",
    "                except:\n",
    "                    speed_kmh = COURIER_SPEED.get(highway, 40)\n",
    "            else:\n",
    "                speed_kmh = COURIER_SPEED.get(highway, 40)\n",
    "            \n",
    "            # calculate time for this segment (seconds to minutes)\n",
    "            segment_time = (length / 1000) / speed_kmh * 60\n",
    "            total_time += segment_time\n",
    "\n",
    "    return total_time\n",
    "\n",
    "# run analysis\n",
    "results = find_closest_warehouse_with_time(order_3857, wh_3857, roads_3857)\n",
    "\n",
    "# join results with orders\n",
    "enhanced_order_3857 = enhanced_order_3857.merge(pd.DataFrame(results), on='order_id', how='left')\n",
    "enhanced_order_3857 = enhanced_order_3857[['fid', 'order_id', 'client_id', 'closest_warehouse', 'profit', 'revenue','distance_m', 'avg_speed_kmh', 'travel_time_min', 'delivery_duration', 'neighbourhood', 'district', 'neighbourhood_id', 'district_id', 'geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09c4735",
   "metadata": {},
   "source": [
    "## Servis Alanları KPI Analizi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8393cea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621a37f0",
   "metadata": {},
   "source": [
    "## Haritalandırma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
